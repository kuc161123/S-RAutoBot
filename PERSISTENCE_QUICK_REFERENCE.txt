================================================================================
TRADING BOT DATA PERSISTENCE & STORAGE LAYERS - QUICK REFERENCE
================================================================================

1. CANDLE STORAGE (OHLCV Historical Data)
   Primary: PostgreSQL
   - Table: candles (15m) and candles_3m (3m) 
   - Schema: symbol, timestamp(ms), OHLCV, volume
   - Index: UNIQUE(symbol, timestamp)
   - Upsert logic: per-row check before insert/update
   - Retention: 30 days default (cleanup_old_candles)
   
   Fallback: SQLite (candles.db)
   - Auto-detection if DATABASE_URL not available
   - Same schema, async-safe (check_same_thread=False)
   
   Save Operations:
   - save_candles(symbol, df) - per symbol
   - save_all_frames(frames) - batch every 15m
   - save_candles_3m(symbol, df) - with exponential backoff retry
   
   Call Sites: live_bot.py lines 2966, 6852, 6864, 6877, 9915, 10644

================================================================================

2. TRADE TRACKER (Executed Trade History)
   Primary: PostgreSQL trades table
   - Fields: symbol, side, entry/exit price/time, pnl_usd, pnl_percent
   - Fields: exit_reason (tp/sl/manual), leverage, strategy_name
   - Indexes: symbol, exit_time, pnl_usd
   - Stats Cache: alltime, last_7d, last_30d (UPSERT on every trade)
   
   Multi-Tier Fallback:
   1. PostgreSQL (atomic transaction)
   2. JSON file (trade_history.json)
   3. Redis backup (trade_history:executed, last 10000)
   
   Load Priority on Startup:
   1. PostgreSQL (last 10000 trades)
   2. Redis (if DB empty)
   3. JSON file (if no Redis)
   4. Start empty
   
   Operations:
   - add_trade(trade) - append + DB insert + cache update + file backup
   - calculate_pnl(entry, exit, qty, side, leverage)
   - get_statistics(days) - win rate, profit factor, by_symbol breakdown
   
   Call Sites: live_bot.py line 7019

================================================================================

3. PHANTOM TRACKER (ML Learning Dataset - All Signals)
   Purpose: Track ALL trading signals (executed + rejected) for ML learning
   
   Redis-Based (Volatile):
   - phantom:active[symbol] - List of in-flight phantoms per symbol
   - phantom:completed - List of closed phantoms (last 1000)
   - phantom:wr:trend/mr/scalp - Rolling window of win/loss outcomes (200)
   - phantom:blocked:YYYYMMDD - Daily signal rejection counter
   
   Data Structure:
   - Symbol, side, entry/sl/tp, signal_time, ml_score
   - was_executed (bool), features (dict), outcome, exit_time
   - Lifecycle flags: tp1_hit, be_moved, time_to_tp1_sec, time_to_exit_sec
   - Enriched labels: one_r_hit, two_r_hit, realized_rr
   
   Lifecycle:
   1. record_signal() - Create phantom, add to active, save to Redis
   2. update_phantom_prices() - Track prices, check TP/SL/timeout
   3. _close_phantom() - Set outcome, feed to ML, save to DB + Redis
   
   PostgreSQL Audit (phantom_persistence.py):
   - phantom_trades_live table - Immutable audit of all phantoms
   - Features stored as JSON text
   - Used for replay/auditing/ML training
   
   Statistics:
   - get_phantom_stats() - total, executed vs rejected, ML accuracy
   - get_learning_data() - Export for ML retraining

================================================================================

4. ML MODEL PERSISTENCE (Redis)
   
   Namespaced Keys (ml:trend:*, with legacy tml:* fallback):
   - ml:trend:completed_trades - Trade count for retrain tracking
   - ml:trend:threshold - Min score (70)
   - ml:trend:model - Base64 pickle (RF + GB + NN ensemble)
   - ml:trend:scaler - StandardScaler pickle
   - ml:trend:calibrator - IsotonicRegression for calibration
   - ml:trend:ev_buckets - Expected value bucketing
   - ml:trend:nn_enabled - Optional NN head flag
   - ml:trend:phantom_weight - Weight for phantom samples
   
   Flow:
   - _load_state() on init - Load models into memory
   - _save_state() after training - Save complete state
   - Models retrain every 50 trades (RETRAIN_INTERVAL)
   - Cold start: 30 trades minimum before training
   
   Win-Rate Guards:
   - phantom:wr:trend - LPUSH outcomes, LTRIM to 200
   - Used by phantom_flow controller to cap relax when WR drops

================================================================================

5. FALLBACK & BACKUP STORAGE
   
   JSON File Backup (trade_history.json):
   - Trade array with all fields serialized
   - Used when PostgreSQL unavailable
   - Fallback on DB transaction failures
   - Entire file rewritten per trade (inefficient but safe)
   
   SQLite Fallback (candles.db):
   - Single-file database for candles
   - No external dependencies
   - Slower than PostgreSQL but reliable
   - Check_same_thread=False for async operations

================================================================================

6. DATA FLOW SUMMARY

   WebSocket → frames dict (memory) → save_candles() → PostgreSQL/SQLite
   
   Signal Detection → record_phantom() → Redis active + memory
   
   Phantom Update → update_phantom_prices() → check TP/SL/timeout
   
   Phantom Close → _close_phantom() → Outcome to ML → PostgreSQL audit
                                   → Redis completed
                                   → Update win-rate list
                                   → Trigger ML retrain check
   
   Trade Execution → add_trade() → PostgreSQL transaction
                                  → trade_stats_cache update
                                  → JSON backup
                                  → Redis backup

================================================================================

7. TIMING & PERFORMANCE

   Save Intervals:
   - Candles: Every 15 minutes (batch) + async on symbol update
   - 3m: As they arrive from WebSocket
   - Trades: Immediately on position close (atomic)
   - Phantoms: Redis (fast), PostgreSQL (audit trail)
   - ML Models: On retrain (every 50 trades)
   
   Latencies:
   - save_all_frames (50 symbols): 50-200ms
   - add_trade: 5-20ms
   - record_phantom: <1ms (Redis)
   - update_phantom_prices: 10-50ms
   - _close_phantom: 20-100ms
   
   Storage Growth:
   - Candles: ~5KB/symbol/month (15m) + ~15KB/symbol/month (3m)
   - Trades: ~500B/trade
   - Phantoms (Redis): ~2KB/phantom (last 1000 only)
   - ML Models: ~50KB total
   - Example 50 symbols: ~25MB/month candles

================================================================================

8. RECOVERY SCENARIOS

   Bot Crash During Trade:
   - Bybit API is source of truth
   - Restart loads trades from DB
   - Position recovery from API if DB missing trade
   - No data loss guaranteed
   
   PostgreSQL Unavailable:
   - Fallback to SQLite for candles
   - JSON file for trades
   - Local memory + Redis for phantoms
   - All data preserved, resync when DB comes back
   
   Redis Down:
   - Local memory phantom tracking continues
   - ML models already loaded
   - Trade history in JSON file
   - Some phantom state loss (minor ML impact)
   
   Railway Restart (Ephemeral Filesystem):
   - PostgreSQL safe (external)
   - Candles recovered from DB
   - Trades recovered from DB
   - Phantoms partially lost (Redis missing)

================================================================================

9. OPERATIONAL CHECKLIST

   Before Going Live:
   ✓ PostgreSQL connection tested
   ✓ SQLite fallback verified
   ✓ Redis optional but recommended
   ✓ cleanup_old_candles() scheduled (cron)
   ✓ Database backups configured
   ✓ trade_history.json location writable
   ✓ candles.db location writable
   ✓ ML directory write permissions
   ✓ Phantom retention policy documented
   ✓ Monitoring alerts configured
   
   Monitoring Points:
   - save_all_frames() success rate (should be 100%)
   - add_trade() latency
   - PostgreSQL availability
   - Redis availability (for ML/phantom)
   - Database size growth

================================================================================

10. KEY COMMANDS & QUERIES

    Database Stats:
    storage.get_stats() → {symbols, total_candles, db_size_mb, type}
    
    Trade Statistics:
    trade_tracker.get_statistics(days=30) → {win_rate, profit_factor, 
                                             top_symbols, worst_symbols, ...}
    
    Phantom Stats:
    phantom_tracker.get_phantom_stats() → {total, executed, rejected,
                                           ml_accuracy, ...}
    
    ML Status:
    ml_scorer.get_retrain_info() → {can_train, trades_until_next_retrain, ...}
    
    Cleanup (Manual):
    storage.cleanup_old_candles(days_to_keep=90)

================================================================================

SUMMARY:
- 4-layer redundancy: PostgreSQL + SQLite + Redis + JSON
- All-or-nothing transaction semantics for trades
- Phantom tracking for ML learning from all signals
- Redis for fast ML state and win-rate monitoring
- PostgreSQL audit trail for compliance/analysis
- Graceful degradation if any single layer fails
- High-frequency 3m support for Scalp strategy

